{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaketerrito/speedchallenge/blob/autoencoder/Feedforward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_xhdPGtxj7JC",
        "colab_type": "code",
        "outputId": "77f6c367-053d-41ac-9206-e8655c8e6c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jaketerrito/speedchallenge/raw/master/data/train.mp4\n",
        "!wget https://github.com/jaketerrito/speedchallenge/raw/master/data/train.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-12 00:18:07--  https://github.com/jaketerrito/speedchallenge/raw/master/data/train.mp4\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/jaketerrito/speedchallenge/master/data/train.mp4 [following]\n",
            "--2019-03-12 00:18:07--  https://media.githubusercontent.com/media/jaketerrito/speedchallenge/master/data/train.mp4\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130034541 (124M) [application/octet-stream]\n",
            "Saving to: ‘train.mp4.1’\n",
            "\n",
            "train.mp4.1         100%[===================>] 124.01M   148MB/s    in 0.8s    \n",
            "\n",
            "2019-03-12 00:18:10 (148 MB/s) - ‘train.mp4.1’ saved [130034541/130034541]\n",
            "\n",
            "--2019-03-12 00:18:11--  https://github.com/jaketerrito/speedchallenge/raw/master/data/train.txt\n",
            "Resolving github.com (github.com)... 192.30.255.112, 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jaketerrito/speedchallenge/master/data/train.txt [following]\n",
            "--2019-03-12 00:18:11--  https://raw.githubusercontent.com/jaketerrito/speedchallenge/master/data/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 194353 (190K) [text/plain]\n",
            "Saving to: ‘train.txt.1’\n",
            "\n",
            "train.txt.1         100%[===================>] 189.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-12 00:18:11 (8.38 MB/s) - ‘train.txt.1’ saved [194353/194353]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0T6eRmqppoIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2 as cv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdB8o5dEnW3f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from os.path import splitext\n",
        "\n",
        "def denseflow(fname, resize_factor):\n",
        "    cap = cv.VideoCapture(fname)\n",
        "    if (cap.isOpened()== False): \n",
        "        print(\"Error opening video stream or file\")\n",
        "        exit()\n",
        "\n",
        "    # Get the video dimensions, 3 is the ordinal value of CV_CAP_PROP_FRAME_WIDTH, 4 is CV_CAP_PROP_FRAME_HEIGHT\n",
        "    # Also resize them because these images are too big\n",
        "    width = int(cap.get(3) / resize_factor)\n",
        "    height = int(cap.get(4) / resize_factor)\n",
        "    shape = (width,height)\n",
        "    size = int(cap.get(7))\n",
        "    ret, frame1 = cap.read()\n",
        "    frame1 = cv.resize(frame1,shape)\n",
        "    prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
        "    hsv = np.zeros_like(frame1)\n",
        "    hsv[...,1] = 255\n",
        "\n",
        "    frames = np.zeros((size,hsv.shape[0],hsv.shape[1],3))\n",
        "    frames[0] = hsv\n",
        "\n",
        "    fcount = 1\n",
        "    t = time.time()\n",
        "\n",
        "    while(1):\n",
        "        ret, frame2 = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame2 = cv.resize(frame2,shape)\n",
        "        next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
        "        flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
        "        hsv[...,0] = ang*180/np.pi/2\n",
        "        hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
        "        frames[fcount] = hsv\n",
        "        prvs = next\n",
        "        fcount += 1\n",
        "    cap.release()\n",
        "\n",
        "    f, ext = splitext(fname)\n",
        "    #np.savez(f+'_op', frames)\n",
        "    return frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjZHiENCnXhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "video = denseflow('train.mp4', 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1SVSXdXrfg5",
        "colab_type": "code",
        "outputId": "b8306c4b-509f-4bff-bf75-4cdc9ee3f792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Processing speeds.\")\n",
        "with open('train.txt') as f:\n",
        "\tspeeds = f.readlines()\n",
        "\tspeeds = np.array([float(x.strip()) for x in speeds])\n",
        "\tspeeds = speeds"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing speeds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yOxcobgvrzsL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv3D, MaxPooling3D, MaxPooling2D, BatchNormalization, Dropout, LeakyReLU, PReLU, Conv2DTranspose, Reshape\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyjLOXobMfAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encoder_generator(video, speeds, batch_size, sequence_length):\n",
        "  while True:\n",
        "    x = []\n",
        "    y = []\n",
        "    while len(x) < batch_size:\n",
        "      frame_num = random.randrange(sequence_length,len(video))\n",
        "      sequence = video[frame_num-sequence_length:frame_num]\n",
        "      '''\n",
        "      flip = random.choice([True,False])\n",
        "      angle = random.uniform(-20,20)\n",
        "      scale = random.uniform(.8,1.2)\n",
        "\n",
        "      for i, image in enumerate(sequence):\n",
        "      # Augmentation\n",
        "      image = skimage.transform.rescale(image, scale=scale)\n",
        "      image = skimage.transform.resize(image, output_shape=sequence[i].shape, mode='constant')\n",
        "      image = skimage.transform.rotate(image, angle=angle)\n",
        "\n",
        "      # Really need to see the types of values before we add this noise\n",
        "      image = image + np.random.normal(scale=.5,size=image.shape)\n",
        "\n",
        "      #normalize input!\n",
        "      image = image / 255\n",
        "      sequence[i] = image\n",
        "      '''\n",
        "      x.append(sequence)\n",
        "      y.append(speeds[frame_num])\n",
        "    yield np.array(x), [np.array(x)[:,-1], np.array(y)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iY6Kbvv0pJzG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "sequence_length = 8\n",
        "epochs = 25\n",
        "split = .9\n",
        "\n",
        "width = video.shape[2]\n",
        "height = video.shape[1]\n",
        "video_size = len(video)\n",
        "\n",
        "train_gen = encoder_generator(video[:int(video_size*split)], speeds[:int(video_size*split)], batch_size, sequence_length)\n",
        "val_gen = encoder_generator(video[int(video_size*split):], speeds[int(video_size*split):], batch_size, sequence_length)\n",
        "\n",
        "# Will return a feature and label set.\t\n",
        "# Features are a list of image sequences in the form: (sequence_length, img_height, img_width, dimensions)\n",
        "def get_encoder():\n",
        "  inputs = Input((sequence_length,height,width,3))\n",
        "\n",
        "  # A convolution being applied to each image seperatey\n",
        "  x = Conv3D(32,(1,3,3),strides=(1,2,2),activation=None)(inputs)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv3D(32,(3,3,3),strides=(2,2,2),activation=None)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv3D(32,(3,3,3),strides=(2,2,2),activation=None)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(.5)(x)\n",
        "\n",
        "  x = Dense(32,activation=None)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  outputs = Dense(16,activation='tanh')(x)\n",
        "  return Model(inputs=inputs,outputs=outputs)\n",
        "  \n",
        "def get_decoder():\n",
        "  inputs = Input((16,))\n",
        "  x = Dense(32,activation=None)(inputs)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = Dense(14*19*32,activation=None)(inputs)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = Reshape((14,19,32))(x)\n",
        "  x = Conv2DTranspose(32,(3,3),strides=(2,2),activation=None)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2DTranspose(32,(3,3),strides=(2,2),activation=None)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2DTranspose(1,(3,3),strides=(2,2),activation=None, output_padding=1)(x)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  \n",
        "  outputs = BatchNormalization()(x)\n",
        "  \n",
        "  return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "def get_predictor():\n",
        "  inputs = Input((16,))\n",
        "  x = Dense(8,activation=None)(inputs)\n",
        "  x = LeakyReLU(alpha=0.1)(x)\n",
        "  outputs = Dense(1,activation='linear')(x)\n",
        "  \n",
        "  return Model(inputs=inputs,outputs=outputs)\n",
        "\n",
        "# build the autoencoder\n",
        "inputs = Input((sequence_length,height,width,3))\n",
        "latent = get_encoder()(inputs)\n",
        "predictor_output = get_predictor()(latent)\n",
        "dec_output = get_decoder()(latent)\n",
        "autoencoder = Model(inputs=inputs,outputs=[dec_output,predictor_output])\n",
        "\n",
        "# compile with mean absolute error loss on reconstructed image and binary_cross for discriminator\n",
        "autoencoder.compile(loss=['mse','mse'],optimizer=RMSprop(), loss_weights=[.5,.5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OIzInI35rkgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46907101-f6d0-49a7-e84c-bcb8e90ac18c"
      },
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit_generator(\n",
        "\ttrain_gen, \n",
        "\tsteps_per_epoch=int(video_size*split/batch_size), \n",
        "\tvalidation_data=val_gen, \n",
        "\tvalidation_steps=int(video_size*(1-split)/batch_size),\n",
        "\tepochs=epochs,\n",
        "\tverbose=True,\n",
        "\tcallbacks=[ModelCheckpoint('./data/weights.hdf5',save_best_only=True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fKkR2yL0rpx5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the training loss against the validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Loss', 'Validation Loss'])\n",
        "plt.savefig(fname='./data/lossplot')\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}