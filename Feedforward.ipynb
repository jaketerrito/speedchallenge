{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaketerrito/speedchallenge/blob/master/Feedforward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_xhdPGtxj7JC",
        "colab_type": "code",
        "outputId": "1ad191e0-4cae-4232-be08-43e349631e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jaketerrito/speedchallenge/raw/master/data/train.mp4\n",
        "!wget https://github.com/jaketerrito/speedchallenge/raw/master/data/train.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-01 23:46:28--  https://github.com/jaketerrito/speedchallenge/raw/master/data/train.mp4\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/jaketerrito/speedchallenge/master/data/train.mp4 [following]\n",
            "--2019-03-01 23:46:28--  https://media.githubusercontent.com/media/jaketerrito/speedchallenge/master/data/train.mp4\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130034541 (124M) [application/octet-stream]\n",
            "Saving to: ‘train.mp4’\n",
            "\n",
            "train.mp4           100%[===================>] 124.01M   156MB/s    in 0.8s    \n",
            "\n",
            "2019-03-01 23:46:30 (156 MB/s) - ‘train.mp4’ saved [130034541/130034541]\n",
            "\n",
            "--2019-03-01 23:46:31--  https://github.com/jaketerrito/speedchallenge/raw/master/data/train.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jaketerrito/speedchallenge/master/data/train.txt [following]\n",
            "--2019-03-01 23:46:31--  https://raw.githubusercontent.com/jaketerrito/speedchallenge/master/data/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 194353 (190K) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>] 189.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-01 23:46:31 (4.87 MB/s) - ‘train.txt’ saved [194353/194353]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0T6eRmqppoIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2 as cv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdB8o5dEnW3f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from os.path import splitext\n",
        "\n",
        "def denseflow(fname, resize_factor):\n",
        "    cap = cv.VideoCapture(fname)\n",
        "    if (cap.isOpened()== False): \n",
        "        print(\"Error opening video stream or file\")\n",
        "        exit()\n",
        "\n",
        "    # Get the video dimensions, 3 is the ordinal value of CV_CAP_PROP_FRAME_WIDTH, 4 is CV_CAP_PROP_FRAME_HEIGHT\n",
        "    # Also resize them because these images are too big\n",
        "    width = int(cap.get(3) / resize_factor)\n",
        "    height = int(cap.get(4) / resize_factor)\n",
        "    shape = (width,height)\n",
        "    size = int(cap.get(7))\n",
        "    ret, frame1 = cap.read()\n",
        "    frame1 = cv.resize(frame1,shape)\n",
        "    prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
        "    hsv = np.zeros_like(frame1)\n",
        "    hsv[...,1] = 255\n",
        "\n",
        "    frames = np.zeros((size,hsv.shape[0],hsv.shape[1],3))\n",
        "    frames[0] = hsv\n",
        "\n",
        "    fcount = 1\n",
        "    t = time.time()\n",
        "\n",
        "    while(1):\n",
        "        ret, frame2 = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame2 = cv.resize(frame2,shape)\n",
        "        next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
        "        flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
        "        hsv[...,0] = ang*180/np.pi/2\n",
        "        hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
        "        frames[fcount] = hsv\n",
        "        prvs = next\n",
        "        fcount += 1\n",
        "    cap.release()\n",
        "\n",
        "    f, ext = splitext(fname)\n",
        "    #np.savez(f+'_op', frames)\n",
        "    return frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjZHiENCnXhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "outputId": "b5f04ef8-61ff-4cc9-dcb8-ea17975ebf52"
      },
      "cell_type": "code",
      "source": [
        "video = denseflow('train.mp4', 4)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9e5813724ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenseflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-ca1c2ec2d273>\u001b[0m in \u001b[0;36mdenseflow\u001b[0;34m(fname, resize_factor)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \"\"\"\n\u001b[0;32m--> 595\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m                 format.write_array(fid, val,\n\u001b[1;32m    697\u001b[0m                                    \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                                    pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    699\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Stage arrays in a temporary file on disk, before writing to zip.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m                     \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'external_loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buffered'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                     buffersize=buffersize, order='C'):\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GLUeuTeInlFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(video, speeds, batch_size, sequence_length):\n",
        "\twhile True:\n",
        "\t\tx = []\n",
        "\t\ty = []\n",
        "\t\twhile len(x) < batch_size:\n",
        "\t\t\tframe_num = random.randrange(sequence_length,len(video))\n",
        "\n",
        "\t\t\tsequence = video[frame_num-sequence_length:frame_num]\n",
        "\t\t\t'''\n",
        "\t\t\tflip = random.choice([True,False])\n",
        "\t\t\tangle = random.uniform(-20,20)\n",
        "\t\t\tscale = random.uniform(.8,1.2)\n",
        "\t\t\t\n",
        "\t\t\tfor i, image in enumerate(sequence):\n",
        "\t\t\t\t# Augmentation\n",
        "\t\t\t\timage = skimage.transform.rescale(image, scale=scale)\n",
        "\t\t\t\timage = skimage.transform.resize(image, output_shape=sequence[i].shape, mode='constant')\n",
        "\t\t\t\timage = skimage.transform.rotate(image, angle=angle)\n",
        "\n",
        "\t\t\t\t# Really need to see the types of values before we add this noise\n",
        "\t\t\t\timage = image + np.random.normal(scale=.5,size=image.shape)\n",
        "\n",
        "\t\t\t\t#normalize input!\n",
        "\t\t\t\timage = image / 255\n",
        "\t\t\t\tsequence[i] = image\n",
        "\t\t\t'''\n",
        "\t\t\tx.append(sequence)\n",
        "\t\t\ty.append(speeds[frame_num])\n",
        "\t\tyield np.array(x), np.array(y)\n",
        "\n",
        "def prediction_generator(video, sequence_length):\n",
        "\ti = 0\n",
        "\twhile True:\n",
        "\n",
        "\t\tyield np.array([video[i:i+sequence_length]])\n",
        "\t\ti += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1SVSXdXrfg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36ddc991-f431-440e-ff54-97ad47c81aa9"
      },
      "cell_type": "code",
      "source": [
        "print(\"Processing speeds.\")\n",
        "with open('train.txt') as f:\n",
        "\tspeeds = f.readlines()\n",
        "\tspeeds = np.array([float(x.strip()) for x in speeds])\n",
        "\tspeeds = speeds"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing speeds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yOxcobgvrzsL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv3D, MaxPooling3D, MaxPooling2D, BatchNormalization, Dropout, LeakyReLU, PReLU\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iY6Kbvv0pJzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "7868d54b-9636-41a1-c89d-c5121485f58b"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "sequence_length = 8\n",
        "epochs = 25\n",
        "split = .9\n",
        "\n",
        "width = video.shape[2]\n",
        "height = video.shape[1]\n",
        "video_size = len(video)\n",
        "\n",
        "train_gen = data_generator(video[:int(video_size*split)], speeds[:int(video_size*split)], batch_size, sequence_length)\n",
        "val_gen = data_generator(video[int(video_size*split):], speeds[int(video_size*split):], batch_size, sequence_length)\n",
        "pred_gen = prediction_generator(video, sequence_length)\n",
        "\n",
        "# Will return a feature and label set.\t\n",
        "# Features are a list of image sequences in the form: (sequence_length, img_height, img_width, dimensions)\n",
        "inputs = Input((sequence_length,height,width,3))\n",
        "\n",
        "# A convolution being applied to each image seperately\n",
        "x = Conv3D(32,(1,3,3),strides=(1,2,2),activation=None)(inputs)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv3D(32,(3,3,3),strides=(2,2,2),activation=None)(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv3D(32,(3,3,3),strides=(2,2,2),activation=None)(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(.5)(x)\n",
        "\n",
        "x = Dense(32,activation=None)(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = Dense(16,activation=None)(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "outputs = Dense(1,activation=None)(x)\n",
        "model = Model(inputs=inputs,outputs=outputs) \n",
        "model.compile(RMSprop(),loss='mean_squared_error')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e582fd915304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvideo_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'video' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OIzInI35rkgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "\ttrain_gen, \n",
        "\tsteps_per_epoch=int(video_size*split/batch_size), \n",
        "\tvalidation_data=val_gen, \n",
        "\tvalidation_steps=int(video_size*(1-split)/batch_size),\n",
        "\tepochs=epochs,\n",
        "\tverbose=True,\n",
        "\tcallbacks=[ModelCheckpoint('./data/weights.hdf5',save_best_only=True)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fKkR2yL0rpx5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = load_model(filepath='./data/weights.hdf5')\n",
        "model2.compile(RMSprop(),loss='mean_squared_error')\n",
        "\n",
        "# Plot the training loss against the validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Loss', 'Validation Loss'])\n",
        "plt.savefig(fname='./data/lossplot')\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "# Plotting predicted speeds against real speeds\n",
        "plt.plot(model2.predict_generator(pred_gen, steps=video_size-sequence_length))\n",
        "plt.plot(speeds)\n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('Speed in mph')\n",
        "plt.legend(['Predicted', 'Real'])\n",
        "plt.savefig(fname='./data/speedplot')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}